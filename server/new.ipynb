{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modip\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "from pymilvus import Collection, connections, FieldSchema, CollectionSchema, DataType\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import json\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "from metaphone import doublemetaphone\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to Zilliz Cloud\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    uri=os.getenv(\"ZILLIZ_URI\"),\n",
    "    token=os.getenv(\"ZILLIZ_TOKEN\")    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection exists.\n",
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"Simple_Embeddings\"\n",
    "collection=''\n",
    "try:\n",
    "    collection = Collection(name=collection_name)  \n",
    "    collection.load()\n",
    "    print(\"Collection exists.\")\n",
    "except Exception as e:\n",
    "    collection = Collection(name=collection_name, schema=schema) \n",
    "    print(\"Collection created.\")\n",
    "\n",
    "\n",
    "if connections.has_connection(\"default\"):\n",
    "    print(\"Connection successful!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(query_vector, stored_vector):\n",
    "    return 1 - cosine(query_vector, stored_vector)\n",
    "\n",
    "def get_metaphone(name):\n",
    "    return doublemetaphone(name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: ['[\"id: 454083262608239335, distance: 0.9999986886978149, entity: {\\'Title_Code\\': \\'BIHHIN05150\\', \\'Title_Name\\': \\'SAMPURNA JAGRAN\\', \\'Metaphone_Name\\': \\'SMPRNJKRN\\'}\", \"id: 454083262608239336, distance: 0.9999986886978149, entity: {\\'Title_Code\\': \\'BIHHIN04876\\', \\'Title_Name\\': \\'SAMPURNA JAGRAN\\', \\'Metaphone_Name\\': \\'SMPRNJKRN\\'}\", \"id: 454083262608239460, distance: 0.9999986886978149, entity: {\\'Title_Code\\': \\'SIKHIN00007\\', \\'Title_Name\\': \\'SAMPURNA JAGRAN\\', \\'Metaphone_Name\\': \\'SMPRNJKRN\\'}\", \"id: 454083262608239331, distance: 0.9999986886978149, entity: {\\'Title_Code\\': \\'BIHHIN05227\\', \\'Title_Name\\': \\'SAMPURNA JAGRAN\\', \\'Metaphone_Name\\': \\'SMPRNJKRN\\'}\", \"id: 454083262608239396, distance: 0.8406250476837158, entity: {\\'Title_Code\\': \\'MAHMAR18580\\', \\'Title_Name\\': \\'SAMAJWADI JAGRAN\\', \\'Metaphone_Name\\': \\'SMJTJKRN\\'}\", \"id: 454083262608239487, distance: 0.7880282402038574, entity: {\\'Title_Code\\': \\'UPHIN05010\\', \\'Title_Name\\': \\'JAUNPUR JAGRAN\\', \\'Metaphone_Name\\': \\'JNPRJKRN\\'}\", \"id: 454083262608239451, distance: 0.7785437107086182, entity: {\\'Title_Code\\': \\'RAJHIN06232\\', \\'Title_Name\\': \\'AMARJAGRAN SAMRAT\\', \\'Metaphone_Name\\': \\'AMRJKRNSMRT\\'}\", \"id: 454083262608239542, distance: 0.7748247981071472, entity: {\\'Title_Code\\': \\'UTTHIN05712\\', \\'Title_Name\\': \\'JANJAGRAN SAMACHAR\\', \\'Metaphone_Name\\': \\'JNJKRNSMKR\\'}\", \"id: 454083262608239429, distance: 0.7687467336654663, entity: {\\'Title_Code\\': \\'MPHIN07422\\', \\'Title_Name\\': \\'JABALPUR JAGRAN\\', \\'Metaphone_Name\\': \\'JPLPRJKRN\\'}\", \"id: 454083262608239485, distance: 0.7562006711959839, entity: {\\'Title_Code\\': \\'UPHIN49761\\', \\'Title_Name\\': \\'MORNING JAGRAN SAMACHAR\\', \\'Metaphone_Name\\': \\'MRNNKJKRNSMKR\\'}\"]'], cost: 6\n"
     ]
    }
   ],
   "source": [
    "# by this approach we will get the vector based on the Title_Name and we will find thode vector only and for this I have created a collection Simple_Embeddings\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# query_metaphone = get_metaphone(\"SAMPURNA JAGRAN\")\n",
    "query_vector = model.encode(\"SAMPURNA JAGRAN\").tolist()\n",
    "results=collection.search(\n",
    "    data=[query_vector],\n",
    "    anns_field=\"vector\",\n",
    "    param={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 384}},\n",
    "    limit=10,\n",
    "    # expr=f\"Metaphone_Name=='{query_metaphone}'\",\n",
    "    output_fields=[\"Metaphone_Name\",\"Title_Code\",\"Title_Name\"]\n",
    ")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorEmbeddings_Based_on_title.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(200):\n",
    "    # f.write(f\"Title Code: {results[0][0].distance}\\n\")\n",
    "    # f.write(f\"Title Name: {results[0][i].entity}\\n\")\n",
    "        f.write(f\"{results[0][i]}\\n\")\n",
    "    # f.write(f\"Score: {result['score']}\\n\")\n",
    "    # f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"Phonetic_Data\"\n",
    "collection=''\n",
    "try:\n",
    "    collection = Collection(name=collection_name)  \n",
    "    collection.load()\n",
    "    print(\"Collection exists.\")\n",
    "except Exception as e:\n",
    "    collection = Collection(name=collection_name, schema=schema) \n",
    "    print(\"Collection created.\")\n",
    "\n",
    "\n",
    "if connections.has_connection(\"default\"):\n",
    "    print(\"Connection successful!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by this approach we will get the vector based on the Metaphone_Name and we will find those vector only and for this I have created a collection Phonetic_Data\n",
    "query_metaphone = get_metaphone(\"SAMPURNA JAGRAN\")\n",
    "query_vector = model.encode(query_metaphone).tolist()\n",
    "results=collection.search(\n",
    "    data=[query_vector],\n",
    "    anns_field=\"vector\",\n",
    "    param={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 384}},\n",
    "    limit=10,\n",
    "    # expr=f\"Metaphone_Name=='{query_metaphone}'\",\n",
    "    output_fields=[\"Metaphone_Name\",\"Title_Code\",\"Title_Name\"]\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id: 453901917307669224, distance: 0.7793334722518921, entity: {'Metaphone_Name': 'JNJKRN', 'Title_Code': 'PUNPUN03786', 'Title_Name': 'JAN JAGRAN'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"vector_Embedings_Based_on_Metaphone.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(200):\n",
    "    # f.write(f\"Title Code: {results[0][0].distance}\\n\")\n",
    "    # f.write(f\"Title Name: {results[0][i].entity}\\n\")\n",
    "        f.write(f\"{results[0][i]}\\n\")\n",
    "    # f.write(f\"Score: {result['score']}\\n\")\n",
    "    # f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method search in module pymilvus.orm.collection:\n",
      "\n",
      "search(data: Union[List, Iterable[Union[Dict[int, float], Iterable[Tuple[int, float]]]], ForwardRef('csc_array'), ForwardRef('coo_array'), ForwardRef('bsr_array'), ForwardRef('dia_array'), ForwardRef('dok_array'), ForwardRef('lil_array'), ForwardRef('csr_array'), ForwardRef('spmatrix')], anns_field: str, param: Dict, limit: int, expr: Optional[str] = None, partition_names: Optional[List[str]] = None, output_fields: Optional[List[str]] = None, timeout: Optional[float] = None, round_decimal: int = -1, **kwargs) method of pymilvus.orm.collection.Collection instance\n",
      "    Conducts a vector similarity search with an optional boolean expression as filter.\n",
      "    \n",
      "    Args:\n",
      "        data (``List[List[float]]/sparse types``): The vectors of search data.\n",
      "            the length of data is number of query (nq),\n",
      "            and the dim of every vector in data must be equal to the vector field of collection.\n",
      "        anns_field (``str``): The name of the vector field used to search of collection.\n",
      "        param (``dict[str, Any]``):\n",
      "            The parameters of search. The followings are valid keys of param.\n",
      "            * *metric_type* (``str``)\n",
      "                similar metricy types, the value must be of type str.\n",
      "            * *offset* (``int``, optional)\n",
      "                offset for pagination.\n",
      "            * *params of index: *nprobe*, *ef*, *search_k*, etc\n",
      "                Corresponding search params for a certain index.\n",
      "            example for param::\n",
      "    \n",
      "                {\n",
      "                    \"metric_type\": \"L2\",\n",
      "                    \"offset\": 10,\n",
      "                    \"params\": {\"nprobe\": 12},\n",
      "                }\n",
      "    \n",
      "        limit (``int``): The max number of returned record, also known as `topk`.\n",
      "        expr (``str``, Optional): The boolean expression used to filter attribute.\n",
      "    \n",
      "            example for expr::\n",
      "    \n",
      "                \"id_field >= 0\", \"id_field in [1, 2, 3, 4]\"\n",
      "    \n",
      "        partition_names (``List[str]``, optional): The names of partitions to search on.\n",
      "        output_fields (``List[str]``, optional):\n",
      "            The name of fields to return in the search result.  Can only get scalar fields.\n",
      "        round_decimal (``int``, optional):\n",
      "            The specified number of decimal places of returned distance.\n",
      "            Defaults to -1 means no round to returned distance.\n",
      "        timeout (``float``, optional): A duration of time in seconds to allow for the RPC.\n",
      "            If timeout is set to None, the client keeps waiting until the server\n",
      "            responds or an error occurs.\n",
      "        **kwargs (``dict``): Optional search params\n",
      "    \n",
      "            *  *_async* (``bool``, optional)\n",
      "                Indicate if invoke asynchronously.\n",
      "                Returns a SearchFuture if True, else returns results from server directly.\n",
      "    \n",
      "            * *_callback* (``function``, optional)\n",
      "                The callback function which is invoked after server response successfully.\n",
      "                It functions only if _async is set to True.\n",
      "    \n",
      "            * *offset* (``int``, optinal)\n",
      "                offset for pagination.\n",
      "    \n",
      "            * *consistency_level* (``str/int``, optional)\n",
      "                Which consistency level to use when searching in the collection.\n",
      "    \n",
      "                Options of consistency level: Strong, Bounded, Eventually, Session, Customized.\n",
      "    \n",
      "                Note: this parameter overwrites the same one specified when creating collection,\n",
      "                if no consistency level was specified, search will use the\n",
      "                consistency level when you create the collection.\n",
      "    \n",
      "            * *guarantee_timestamp* (``int``, optional)\n",
      "                Instructs Milvus to see all operations performed before this timestamp.\n",
      "                By default Milvus will search all operations performed to date.\n",
      "    \n",
      "                Note: only valid in Customized consistency level.\n",
      "    \n",
      "            * *graceful_time* (``int``, optional)\n",
      "                Search will use the (current_timestamp - the graceful_time) as the\n",
      "                `guarantee_timestamp`. By default with 5s.\n",
      "    \n",
      "                Note: only valid in Bounded consistency level\n",
      "    \n",
      "    Returns:\n",
      "        SearchResult:\n",
      "            Returns ``SearchResult`` if `_async` is False , otherwise ``SearchFuture``\n",
      "    \n",
      "    .. _Metric type documentations:\n",
      "        https://milvus.io/docs/v2.2.x/metric.md\n",
      "    .. _Index documentations:\n",
      "        https://milvus.io/docs/v2.2.x/index.md\n",
      "    .. _How guarantee ts works:\n",
      "        https://github.com/milvus-io/milvus/blob/master/docs/developer_guides/how-guarantee-ts-works.md\n",
      "    \n",
      "    Raises:\n",
      "        MilvusException: If anything goes wrong\n",
      "    \n",
      "    Examples:\n",
      "        >>> from pymilvus import Collection, FieldSchema, CollectionSchema, DataType\n",
      "        >>> import random\n",
      "        >>> schema = CollectionSchema([\n",
      "        ...     FieldSchema(\"film_id\", DataType.INT64, is_primary=True),\n",
      "        ...     FieldSchema(\"films\", dtype=DataType.FLOAT_VECTOR, dim=2)\n",
      "        ... ])\n",
      "        >>> collection = Collection(\"test_collection_search\", schema)\n",
      "        >>> # insert\n",
      "        >>> data = [\n",
      "        ...     [i for i in range(10)],\n",
      "        ...     [[random.random() for _ in range(2)] for _ in range(10)],\n",
      "        ... ]\n",
      "        >>> collection.insert(data)\n",
      "        >>> index_param = {\"index_type\": \"FLAT\", \"metric_type\": \"L2\", \"params\": {}}\n",
      "        >>> collection.create_index(\"films\", index_param)\n",
      "        >>> collection.load()\n",
      "        >>> # search\n",
      "        >>> search_param = {\n",
      "        ...     \"data\": [[1.0, 1.0]],\n",
      "        ...     \"anns_field\": \"films\",\n",
      "        ...     \"param\": {\"metric_type\": \"L2\", \"offset\": 1},\n",
      "        ...     \"limit\": 2,\n",
      "        ...     \"expr\": \"film_id > 0\",\n",
      "        ... }\n",
      "        >>> res = collection.search(**search_param)\n",
      "        >>> assert len(res) == 1\n",
      "        >>> hits = res[0]\n",
      "        >>> assert len(hits) == 2\n",
      "        >>> print(f\"- Total hits: {len(hits)}, hits ids: {hits.ids} \")\n",
      "        - Total hits: 2, hits ids: [8, 5]\n",
      "        >>> print(f\"- Top1 hit id: {hits[0].id}, score: {hits[0].score} \")\n",
      "        - Top1 hit id: 8, score: 0.10143111646175385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(collection.search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyphonetics in c:\\users\\modip\\anaconda3\\envs\\sarthi\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: unidecode<2,>=1 in c:\\users\\modip\\anaconda3\\envs\\sarthi\\lib\\site-packages (from pyphonetics) (1.3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyphonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphonetics import RefinedSoundex\n",
    "rs=RefinedSoundex()\n",
    "rs.distance(\"VIDHYA JAaGRAN\",\"VIDISHA JAGRAN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarthi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "from pymilvus import Collection, connections, FieldSchema, CollectionSchema, DataType\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import List\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "from metaphone import doublemetaphone\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to Zilliz Cloud\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    uri=os.getenv(\"ZILLIZ_URI\"),\n",
    "    token=os.getenv(\"ZILLIZ_TOKEN\")    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection exists.\n",
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"Simple_Embeddings\"\n",
    "collection=''\n",
    "try:\n",
    "    collection = Collection(name=collection_name)  \n",
    "    collection.load()\n",
    "    print(\"Collection exists.\")\n",
    "except Exception as e:\n",
    "    collection = Collection(name=collection_name, schema=schema) \n",
    "    print(\"Collection created.\")\n",
    "\n",
    "\n",
    "if connections.has_connection(\"default\"):\n",
    "    print(\"Connection successful!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(query_vector, stored_vector):\n",
    "    return 1 - cosine(query_vector, stored_vector)\n",
    "\n",
    "def get_metaphone(name):\n",
    "    return doublemetaphone(name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymilvus.orm.iterator.QueryIterator object at 0x000001D52F8FD330>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    text2=\"\"\n",
    "    iterator = collection.query_iterator(\n",
    "        expr=\"\",\n",
    "        output_fields=[\"Title_Name\"]\n",
    "    )\n",
    "    print(iterator)\n",
    "    results = []\n",
    "    while True:\n",
    "        result=iterator.next()\n",
    "        if not result:\n",
    "            iterator.close()\n",
    "            break\n",
    "        df=pd.DataFrame(result)\n",
    "        text2 += \" \".join(title for title in df['Title_Name'])\n",
    "    #    print(text2)\n",
    "        results+=result\n",
    "    #    word_cloud2 = WordCloud(collocations = False, background_color = 'white').generate(text2)\n",
    "    #    word_frequencies = word_cloud2.words_\n",
    "    words = text2.split()\n",
    "    total = Counter(words)\n",
    "    title_name=np.array(list(total.keys()))\n",
    "    word_count = np.array(list(total.values()), dtype=np.int32)\n",
    "    count_df=pd.DataFrame({'Title_Name':title_name,'Word_Count':word_count})\n",
    "    count_df = count_df.sort_values(by=\"Word_Count\", ascending=False).reset_index(drop=True)\n",
    "    #    word_cloud2.to_file(\"word_cloud.png\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df\n",
    "count_df.to_csv('word_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymilvus.orm.iterator.SearchIterator object at 0x0000022EB8BB5780>\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# by this approach we will get the vector based on the Title_Name and we will find thode vector only and for this I have created a collection Simple_Embeddings\n",
    "\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# query_metaphone = get_metaphone(\"SAMPURNA JAGRAN\")\n",
    "results=[]\n",
    "all_data=[]\n",
    "lower_bound=0.6 #radius\n",
    "upper_bound=0.8 #range_filter\n",
    "query_vector = model.encode(\"ANUSUCHIT TIMES\").tolist()\n",
    "iterator=collection.search_iterator(\n",
    "    data=[query_vector],\n",
    "    anns_field=\"vector\",\n",
    "    param={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 384,}},\n",
    "    limit=500,\n",
    "    # expr=f\"Metaphone_Name=='{query_metaphone}'\",\n",
    "    output_fields=[\"Metaphone_Name\",\"Title_Code\",\"Title_Name\"]\n",
    ")\n",
    "print(iterator)\n",
    "while True:\n",
    "    result = iterator.next()\n",
    "    if not result:\n",
    "        iterator.close()\n",
    "        break\n",
    "    \n",
    "    for hit in result:\n",
    "        results.append(hit.to_dict())\n",
    "        \n",
    "print(len(results))\n",
    "for i in range(0,len(results)):\n",
    "    all_data.append({\n",
    "        \"Title_Code\":results[i]['entity']['Title_Code'],\n",
    "        \"Title_Name\":results[i]['entity']['Title_Name'],\n",
    "        \"Metaphone_Name\":results[i]['entity']['Metaphone_Name'],\n",
    "        \"distance\":results[i]['distance']\n",
    "    })\n",
    "df=pd.DataFrame(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_Code</th>\n",
       "      <th>Title_Name</th>\n",
       "      <th>Metaphone_Name</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPHIN30203</td>\n",
       "      <td>ANUSUCHIT JATI TIMES</td>\n",
       "      <td>ANSXTJTTMS</td>\n",
       "      <td>0.820419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHHHIN16004</td>\n",
       "      <td>ANUMODAN TIMES</td>\n",
       "      <td>ANMTNTMS</td>\n",
       "      <td>0.737099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIHHIN11744</td>\n",
       "      <td>ANIWESH TIMES</td>\n",
       "      <td>ANXTMS</td>\n",
       "      <td>0.714466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UPHIN45726</td>\n",
       "      <td>ANURAG TIMES</td>\n",
       "      <td>ANRKTMS</td>\n",
       "      <td>0.712113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIHHIN00188</td>\n",
       "      <td>ANURADHA TIMES</td>\n",
       "      <td>ANRTTMS</td>\n",
       "      <td>0.706303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>HARBIL00293</td>\n",
       "      <td>SIRSA TIMES</td>\n",
       "      <td>SRSTMS</td>\n",
       "      <td>0.485763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>UTTHIN00113</td>\n",
       "      <td>AHERIYA TIMES</td>\n",
       "      <td>AHRTMS</td>\n",
       "      <td>0.485755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>MPHIN17381</td>\n",
       "      <td>AHANA TIMES</td>\n",
       "      <td>AHNTMS</td>\n",
       "      <td>0.485671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>APENG03078</td>\n",
       "      <td>SEEMA TIMES</td>\n",
       "      <td>SMTMS</td>\n",
       "      <td>0.485610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>PUNHIN01512</td>\n",
       "      <td>SEEMA TIMES</td>\n",
       "      <td>SMTMS</td>\n",
       "      <td>0.485610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Title_Code            Title_Name Metaphone_Name  distance\n",
       "0     UPHIN30203  ANUSUCHIT JATI TIMES     ANSXTJTTMS  0.820419\n",
       "1    CHHHIN16004        ANUMODAN TIMES       ANMTNTMS  0.737099\n",
       "2    BIHHIN11744         ANIWESH TIMES         ANXTMS  0.714466\n",
       "3     UPHIN45726          ANURAG TIMES        ANRKTMS  0.712113\n",
       "4    BIHHIN00188        ANURADHA TIMES        ANRTTMS  0.706303\n",
       "..           ...                   ...            ...       ...\n",
       "495  HARBIL00293           SIRSA TIMES         SRSTMS  0.485763\n",
       "496  UTTHIN00113         AHERIYA TIMES         AHRTMS  0.485755\n",
       "497   MPHIN17381           AHANA TIMES         AHNTMS  0.485671\n",
       "498   APENG03078           SEEMA TIMES          SMTMS  0.485610\n",
       "499  PUNHIN01512           SEEMA TIMES          SMTMS  0.485610\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ANUSUCHIT JATI TIMES\n",
       "1            ANUMODAN TIMES\n",
       "2             ANIWESH TIMES\n",
       "3              ANURAG TIMES\n",
       "4            ANURADHA TIMES\n",
       "               ...         \n",
       "495             SIRSA TIMES\n",
       "496           AHERIYA TIMES\n",
       "497             AHANA TIMES\n",
       "498             SEEMA TIMES\n",
       "499             SEEMA TIMES\n",
       "Name: Title_Name, Length: 500, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 454083262685460103, 'distance': 0.9999986290931702, 'entity': {'Metaphone_Name': 'SMPRNJKRN', 'Title_Code': 'BIHHIN04876', 'Title_Name': 'SAMPURNA JAGRAN'}}, {'id': 454083262685460227, 'distance': 0.9999986290931702, 'entity': {'Metaphone_Name': 'SMPRNJKRN', 'Title_Code': 'SIKHIN00007', 'Title_Name': 'SAMPURNA JAGRAN'}}, {'id': 454083262685460098, 'distance': 0.9999986290931702, 'entity': {'Metaphone_Name': 'SMPRNJKRN', 'Title_Code': 'BIHHIN05227', 'Title_Name': 'SAMPURNA JAGRAN'}}, {'id': 454083262685460102, 'distance': 0.9999986290931702, 'entity': {'Metaphone_Name': 'SMPRNJKRN', 'Title_Code': 'BIHHIN05150', 'Title_Name': 'SAMPURNA JAGRAN'}}, {'id': 454083262685460163, 'distance': 0.8406250476837158, 'entity': {'Metaphone_Name': 'SMJTJKRN', 'Title_Code': 'MAHMAR18580', 'Title_Name': 'SAMAJWADI JAGRAN'}}, {'id': 454083262685460254, 'distance': 0.7880282402038574, 'entity': {'Metaphone_Name': 'JNPRJKRN', 'Title_Code': 'UPHIN05010', 'Title_Name': 'JAUNPUR JAGRAN'}}, {'id': 454083262685460218, 'distance': 0.7785437107086182, 'entity': {'Metaphone_Name': 'AMRJKRNSMRT', 'Title_Code': 'RAJHIN06232', 'Title_Name': 'AMARJAGRAN SAMRAT'}}, {'id': 454083262685460309, 'distance': 0.7748247981071472, 'entity': {'Metaphone_Name': 'JNJKRNSMKR', 'Title_Code': 'UTTHIN05712', 'Title_Name': 'JANJAGRAN SAMACHAR'}}, {'id': 454083262685460196, 'distance': 0.7687467336654663, 'entity': {'Metaphone_Name': 'JPLPRJKRN', 'Title_Code': 'MPHIN07422', 'Title_Name': 'JABALPUR JAGRAN'}}, {'id': 454083262685460252, 'distance': 0.7562006711959839, 'entity': {'Metaphone_Name': 'MRNNKJKRNSMKR', 'Title_Code': 'UPHIN49761', 'Title_Name': 'MORNING JAGRAN SAMACHAR'}}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "while True:\n",
    "    result = iterator.next()\n",
    "    if not result:\n",
    "        iterator.close()\n",
    "        break\n",
    "    \n",
    "    for hit in result:\n",
    "        results.append(hit.to_dict())\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 454083262683687856, 'distance': 0.7012470364570618, 'entity': {'Metaphone_Name': 'ANTNSMKR', 'Title_Code': 'DELURD00579', 'Title_Name': 'INDIAN SAMACHAR'}}, {'id': 454083262683690036, 'distance': 0.69939124584198, 'entity': {'Metaphone_Name': 'SMKRNT', 'Title_Code': 'UPHIN35849', 'Title_Name': 'SAMACHAR INDIA'}}, {'id': 454083262683689733, 'distance': 0.6977645754814148, 'entity': {'Metaphone_Name': 'SMRNT', 'Title_Code': 'UPHIN45242', 'Title_Name': 'SAMAR INDIA'}}, {'id': 454083262683689732, 'distance': 0.6977645754814148, 'entity': {'Metaphone_Name': 'SMRNT', 'Title_Code': 'UPHIN48348', 'Title_Name': 'SAMAR INDIA'}}, {'id': 454083262683690096, 'distance': 0.695911169052124, 'entity': {'Metaphone_Name': 'SMNJSNT', 'Title_Code': 'UPHIN45165', 'Title_Name': 'SAMANJASYA INDIA'}}, {'id': 454083262683689229, 'distance': 0.6795110106468201, 'entity': {'Metaphone_Name': 'SMTNNT', 'Title_Code': 'RAJHIN17513', 'Title_Name': 'SAMADHAN INDIA'}}, {'id': 454083262683689004, 'distance': 0.67850261926651, 'entity': {'Metaphone_Name': 'JKRTNT', 'Title_Code': 'MPHIN21892', 'Title_Name': 'JAGRAT INDIA'}}, {'id': 454083262683686703, 'distance': 0.6756516695022583, 'entity': {'Metaphone_Name': 'ANTSMKRM', 'Title_Code': 'APTEL11926', 'Title_Name': 'INDIA SAMACHARAM'}}, {'id': 454083262683688829, 'distance': 0.6570177674293518, 'entity': {'Metaphone_Name': 'ANTSMRT', 'Title_Code': 'MAHHIN05726', 'Title_Name': 'INDIA SAMRAT'}}, {'id': 454083262683688806, 'distance': 0.6570177674293518, 'entity': {'Metaphone_Name': 'ANTSMRT', 'Title_Code': 'MAHMAR25468', 'Title_Name': 'INDIA SAMRAT'}}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorEmbeddings_Based_on_title.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(200):\n",
    "    # f.write(f\"Title Code: {results[0][0].distance}\\n\")\n",
    "    # f.write(f\"Title Name: {results[0][i].entity}\\n\")\n",
    "        f.write(f\"{results[0][i]}\\n\")\n",
    "    # f.write(f\"Score: {result['score']}\\n\")\n",
    "    # f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection exists.\n",
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"Two_Vectors\"\n",
    "collection=''\n",
    "try:\n",
    "    collection = Collection(name=collection_name)  \n",
    "    collection.load()\n",
    "    print(\"Collection exists.\")\n",
    "except Exception as e:\n",
    "    collection = Collection(name=collection_name, schema=schema) \n",
    "    print(\"Collection created.\")\n",
    "\n",
    "\n",
    "if connections.has_connection(\"default\"):\n",
    "    print(\"Connection successful!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: ['[\"id: 454083262671860672, distance: 0.8563528060913086, entity: {\\'Title_Name\\': \\'BRAJ KI AAWAZ\\', \\'NYSIIS_Name\\': \\'BRAJC\\'}\", \"id: 454083262671860291, distance: 0.8563528060913086, entity: {\\'Title_Name\\': \\'PRAJA KI AWAZ\\', \\'NYSIIS_Name\\': \\'PRAJAC\\'}\", \"id: 454083262671846554, distance: 0.8186184763908386, entity: {\\'Title_Name\\': \\'BHARAT TIMES SAJAG\\', \\'NYSIIS_Name\\': \\'BARATANASAJAG\\'}\", \"id: 454083262671846629, distance: 0.8186184763908386, entity: {\\'Title_Name\\': \\'BHARAT TIMES SAJAG\\', \\'NYSIIS_Name\\': \\'BARATANASAJAG\\'}\", \"id: 454083262671847233, distance: 0.8186184763908386, entity: {\\'Title_Name\\': \\'BHARAT TIMES SAJAG\\', \\'NYSIIS_Name\\': \\'BARATANASAJAG\\'}\", \"id: 454083262671854863, distance: 0.8093137145042419, entity: {\\'Title_Name\\': \\'PROJECTS TODAY\\', \\'NYSIIS_Name\\': \\'PRAJACTSTADY\\'}\", \"id: 454083262671850229, distance: 0.7847380042076111, entity: {\\'Title_Name\\': \\'PROJECTOR TIMES\\', \\'NYSIIS_Name\\': \\'PRAJACTARTAN\\'}\", \"id: 454083262671855989, distance: 0.7699467539787292, entity: {\\'Title_Name\\': \\'PROJECT MANAGEMENT TODAY\\', \\'NYSIIS_Name\\': \\'PRAJACTNANAGANANTADY\\'}\", \"id: 454083262671857389, distance: 0.7656092643737793, entity: {\\'Title_Name\\': \\'JAGO INDIA JAGO\\', \\'NYSIIS_Name\\': \\'JAGANDAJAG\\'}\", \"id: 454083262671850177, distance: 0.7553633451461792, entity: {\\'Title_Name\\': \\'BHARATIYA JAG TIMES\\', \\'NYSIIS_Name\\': \\'BARATYAJAGTAN\\'}\"] ... and 103 entities remaining'], cost: 6\n"
     ]
    }
   ],
   "source": [
    "# by this approach we will get the vector based on the Metaphone_Name and we will find those vector only and for this I have created a collection Phonetic_Data\n",
    "query_metaphone = get_metaphone(\"BRAJ KI AAWAZ JAGRAN\")\n",
    "query_vector = model.encode(query_metaphone).tolist()\n",
    "results=collection.search(\n",
    "    data=[query_vector],\n",
    "    anns_field=\"vector_of_metaphone\",\n",
    "    param={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 384}},\n",
    "    limit=200,\n",
    "    # expr=f\"Metaphone_Name=='{query_metaphone}'\",\n",
    "    output_fields=[\"Title_Name\",\"NYSIIS_Name\"]\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorEmbeddings_Based_on_title.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for result in results[0]:\n",
    "    # f.write(f\"Title Code: {results[0][0].distance}\\n\")\n",
    "    # f.write(f\"Title Name: {results[0][i].entity}\\n\")\n",
    "        f.write(f\"{result.entity.get('Title_Name')}\\n\")\n",
    "    # f.write(f\"Score: {result['score']}\\n\")\n",
    "    # f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode both metaphone and title vectors\n",
    "name=\"GRAMIN PARTIDIN\"\n",
    "query_metaphone_vector = model.encode(get_metaphone(name)).tolist()\n",
    "query_title_vector = model.encode(name).tolist()\n",
    "\n",
    "# Search on Metaphone vector\n",
    "results_metaphone = collection.search(\n",
    "    data=[query_metaphone_vector],\n",
    "    anns_field=\"vector_of_metaphone\",\n",
    "    param={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 384}},\n",
    "    limit=200,\n",
    "    output_fields=[\"Title_Name\", \"Metaphone_Name\"]\n",
    ")\n",
    "\n",
    "# Search on Title_Name vector\n",
    "results_title = collection.search(\n",
    "    data=[query_title_vector],\n",
    "    anns_field=\"vector_of_name\",\n",
    "    param={\"metric_type\": \"COSINE\", \"params\": {\"nprobe\": 384}},\n",
    "    limit=200,\n",
    "    output_fields=[\"Title_Name\", \"Metaphone_Name\"]\n",
    ")\n",
    "\n",
    "# Combine and rank results (example combining scores)\n",
    "combined_results = []\n",
    "\n",
    "# for res_metaphone, res_title in zip(results_metaphone, results_title):\n",
    "#     combined_score = 0.5 * res_metaphone.score + 0.5 * res_title.score  # Weighted average\n",
    "#     combined_results.append({\n",
    "#         \"Title_Name\": res_metaphone.entity.Title_Name,  # Prefer Metaphone's title\n",
    "#         \"Metaphone_Name\": res_metaphone.entity.NYSIIS_Name,\n",
    "#         \"Combined_Score\": combined_score\n",
    "#     })\n",
    "\n",
    "for i in range(50):\n",
    "    print(f\"Name->{name}\\n\")\n",
    "    print(f\"Metaphone->{get_metaphone(name)}\\n\")\n",
    "    print(f\"{results_metaphone[0][i]}\\n\")\n",
    "    print(f\"{results_title[0][i]}\\n\\n\\n\")\n",
    "\n",
    "# Sort by combined score\n",
    "combined_results = sorted(combined_results, key=lambda x: x[\"Combined_Score\"], reverse=True)\n",
    "\n",
    "print(\"Combined Results:\")\n",
    "print(combined_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "            # data=[query_vector],\n",
    "            # anns_field=\"vector\",\n",
    "            # param=search_params,\n",
    "            limit=1500,\n",
    "            expr=f\"\",\n",
    "            output_fields=[\"Title_Name\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SAMPURNA JAGRAN'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[7]['Title_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vector_Embedings_Based_on_Metaphone.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(200):\n",
    "    # f.write(f\"Title Code: {results[0][0].distance}\\n\")\n",
    "    # f.write(f\"Title Name: {results[0][i].entity}\\n\")\n",
    "        f.write(f\"{results[0][i]}\\n\")\n",
    "        # f.write(f\"{results[0][i].entity.Title_Name}\\n\")\n",
    "        # f.write(f\"{results[i]['Title_Name']}\\n\")\n",
    "    # f.write(f\"Score: {result['score']}\\n\")\n",
    "    # f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyphonetics in c:\\users\\modip\\anaconda3\\envs\\sarthi\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: unidecode<2,>=1 in c:\\users\\modip\\anaconda3\\envs\\sarthi\\lib\\site-packages (from pyphonetics) (1.3.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyphonetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphonetics import RefinedSoundex\n",
    "rs=RefinedSoundex()\n",
    "rs.distance(\"VIDHYA JAaGRAN\",\"VIDISHA JAGRAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         TIMES\n",
      "1         INDIA\n",
      "2         TODAY\n",
      "3        INDIAN\n",
      "4            OF\n",
      "5           THE\n",
      "6          AWAZ\n",
      "7       JOURNAL\n",
      "8            KI\n",
      "9          NEWS\n",
      "10       JAGRAN\n",
      "11          AND\n",
      "12        AAWAZ\n",
      "13          NEW\n",
      "14          ALL\n",
      "15            &\n",
      "16       SUNDAY\n",
      "17          LAW\n",
      "18     ECONOMIC\n",
      "19      EXPRESS\n",
      "20       BHARAT\n",
      "21         CITY\n",
      "22           IN\n",
      "23     BULLETIN\n",
      "24          JAN\n",
      "25       REVIEW\n",
      "26      MEDICAL\n",
      "27       DAINIK\n",
      "28     SAMACHAR\n",
      "29            E\n",
      "30    RASHTRIYA\n",
      "31      PRADESH\n",
      "32      SOCIETY\n",
      "33    EDUCATION\n",
      "34      TRIBUNE\n",
      "Name: Title_Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def load_dictionary(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [line.strip() for line in file]\n",
    "\n",
    "def wagner_fischer(s1, s2):\n",
    "    len_s1, len_s2 = len(s1), len(s2)\n",
    "    if len_s1 > len_s2:\n",
    "        s1, s2 = s2, s1\n",
    "        len_s1, len_s2 = len_s2, len_s1\n",
    "\n",
    "    current_row = range(len_s1 + 1)\n",
    "    for i in range(1, len_s2 + 1):\n",
    "        previous_row, current_row = current_row, [i] + [0] * len_s1\n",
    "        for j in range(1, len_s1 + 1):\n",
    "            add, delete, change = previous_row[j] + 1, current_row[j-1] + 1, previous_row[j-1]\n",
    "            if s1[j-1] != s2[i-1]:\n",
    "                change += 1\n",
    "            current_row[j] = min(add, delete, change)\n",
    "\n",
    "    return current_row[len_s1]\n",
    "\n",
    "def spell_check(word, dictionary):\n",
    "    suggestions = []\n",
    "\n",
    "    for correct_word in dictionary:\n",
    "        distance = wagner_fischer(word, correct_word)\n",
    "        suggestions.append((correct_word, distance))\n",
    "\n",
    "    suggestions.sort(key=lambda x: x[1])\n",
    "    return suggestions[:100]\n",
    "\n",
    "# Example Usage\n",
    "count_df=pd.read_csv('word_counts.csv')\n",
    "thres_words=count_df.loc[count_df['Word_Count']>=50]['Title_Name']\n",
    "print(thres_words)\n",
    "# dictionary = load_dictionary(\"vectorEmbeddings_Based_on_title.txt\")\n",
    "misspelled_word = \"ANUSUCHIT JAGRITI TIMES\"\n",
    "# suggestions = spell_check(misspelled_word,df['Title_Name'])\n",
    "# print(f\"Top 10 suggestions for '{misspelled_word}':\")\n",
    "# for word, distance in suggestions:\n",
    "#     print(f\"{word} (Distance: {distance})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Levenshtein==0.26.1 (from python-Levenshtein)\n",
      "  Downloading levenshtein-0.26.1-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n",
      "  Downloading rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
      "Downloading levenshtein-0.26.1-cp310-cp310-win_amd64.whl (98 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.9 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "fuzz.ratio(\"Book\",\"Books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "Str1 = \"VIDHYA JAGRAN\"\n",
    "Str2 = \"VISHWA JAGRAN\"\n",
    "print(fuzz.token_sort_ratio(Str1,Str2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarthi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

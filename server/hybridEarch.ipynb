{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "from pymilvus import Collection, connections, FieldSchema, CollectionSchema, DataType\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import json\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "from metaphone import doublemetaphone\n",
    "from pymilvus import AnnSearchRequest\n",
    "from pymilvus import WeightedRanker\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to Zilliz Cloud\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    uri=os.getenv(\"ZILLIZ_URI\"),\n",
    "    token=os.getenv(\"ZILLIZ_TOKEN\")    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection exists.\n",
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"All_Words_Count_List\"\n",
    "collection=''\n",
    "try:\n",
    "    collection = Collection(name=collection_name)  \n",
    "    collection.load()\n",
    "    print(\"Collection exists.\")\n",
    "except Exception as e:\n",
    "    collection = Collection(name=collection_name, schema=schema) \n",
    "    print(\"Collection created.\")\n",
    "\n",
    "\n",
    "if connections.has_connection(\"default\"):\n",
    "    print(\"Connection successful!\")\n",
    "else:\n",
    "    print(\"Failed to connect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metaphone(name):\n",
    "    return doublemetaphone(name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anns_field': 'vector_of_name', 'param': {'metric_type': 'COSINE', 'params': {'nprobe': 384}}, 'limit': 200, 'expr': None}\n",
      "{'anns_field': 'vector_of_metaphone', 'param': {'metric_type': 'COSINE', 'params': {'nprobe': 384}}, 'limit': 200, 'expr': None}\n"
     ]
    }
   ],
   "source": [
    "# Create ANN search request 1 for filmVector\n",
    "# query_filmVector = [[0.8896863042430693, 0.370613100114602, 0.23779315077113428, 0.38227915951132996, 0.5997064603128835]]\n",
    "nameVector=[model.encode(\"NEELI GAGAN SAMACHAR TIMES\").tolist()]\n",
    "\n",
    "search_param_1 = {\n",
    "    \"data\": nameVector, # Query vector\n",
    "    \"anns_field\": \"vector_of_name\", # Vector field name\n",
    "    \"param\": {\n",
    "        \"metric_type\": \"COSINE\", # This parameter value must be identical to the one used in the collection schema\n",
    "        \"params\": {\"nprobe\": 384}\n",
    "    },\n",
    "    \"limit\": 200, # Number of search results to return in this AnnSearchRequest,\n",
    "}\n",
    "request_1 = AnnSearchRequest(**search_param_1)\n",
    "\n",
    "# Create ANN search request 2 for posterVector\n",
    "# query_posterVector = [[0.02550758562349764, 0.006085637357292062, 0.5325251250159071, 0.7676432650114147, 0.5521074424751443]]\n",
    "metaphoneVector=[model.encode(get_metaphone('NEELI GAGAN SAMACHAR TIMES')).tolist()]\n",
    "search_param_2 = {\n",
    "    \"data\": metaphoneVector, # Query vector\n",
    "    \"anns_field\": \"vector_of_metaphone\", # Vector field name\n",
    "    \"param\": {\n",
    "        \"metric_type\": \"COSINE\", # This parameter value must be identical to the one used in the collection schema\n",
    "        \"params\": {\"nprobe\": 384}\n",
    "    },\n",
    "    \"limit\": 200, # Number of search results to return in this AnnSearchRequest\n",
    "}\n",
    "request_2 = AnnSearchRequest(**search_param_2)\n",
    "print(request_1)\n",
    "print(request_2)\n",
    "\n",
    "# Store these two requests as a list in `reqs`\n",
    "reqs = [request_1, request_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank = WeightedRanker(0.8, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.hybrid_search(\n",
    "    reqs, # List of AnnSearchRequests created in step 1\n",
    "    rerank, # Reranking strategy specified in step 2\n",
    "    limit=200, # Number of final search results to return,\n",
    "    output_fields=[\"Metaphone_Name\",\"Title_Code\",\"Title_Name\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results = []\n",
    "for result in results[0]:\n",
    "    processed_results.append({\n",
    "        \"distance\": result.distance,\n",
    "        \"Metaphone_Name\": result.entity.get(\"Metaphone_Name\"),\n",
    "        \"Title_Code\": result.entity.get(\"Title_Code\"),\n",
    "        \"Title_Name\": result.entity.get(\"Title_Name\"),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_search_results=pd.DataFrame(processed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>Metaphone_Name</th>\n",
       "      <th>Title_Code</th>\n",
       "      <th>Title_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>ANSXTJTTMS</td>\n",
       "      <td>UPHIN30203</td>\n",
       "      <td>ANUSUCHIT JATI TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866217</td>\n",
       "      <td>JKRTTMS</td>\n",
       "      <td>JKENG00746</td>\n",
       "      <td>JAGRATI TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.833722</td>\n",
       "      <td>ANXTMS</td>\n",
       "      <td>BIHHIN11744</td>\n",
       "      <td>ANIWESH TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830987</td>\n",
       "      <td>JSRTTMS</td>\n",
       "      <td>DELURD02896</td>\n",
       "      <td>JASARAT TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830987</td>\n",
       "      <td>JSRTTMS</td>\n",
       "      <td>DELBIL06518</td>\n",
       "      <td>JASARAT TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.165786</td>\n",
       "      <td>TSTJRTMS</td>\n",
       "      <td>MPHIN34395</td>\n",
       "      <td>DASTGEER TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.165721</td>\n",
       "      <td>JTXRTMS</td>\n",
       "      <td>RAJHIN27392</td>\n",
       "      <td>JODHESHWAR TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.165661</td>\n",
       "      <td>MJTTMS</td>\n",
       "      <td>UPHIN47530</td>\n",
       "      <td>MAJEET TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.165532</td>\n",
       "      <td>RXTRLKMTTMS</td>\n",
       "      <td>UPHIN49259</td>\n",
       "      <td>RASHTRIYA LOKMAT TIMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.165407</td>\n",
       "      <td>ATRXTMS</td>\n",
       "      <td>UPHIN13828</td>\n",
       "      <td>ADARSH TIMES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     distance Metaphone_Name   Title_Code              Title_Name\n",
       "0    0.999999     ANSXTJTTMS   UPHIN30203    ANUSUCHIT JATI TIMES\n",
       "1    0.866217        JKRTTMS   JKENG00746           JAGRATI TIMES\n",
       "2    0.833722         ANXTMS  BIHHIN11744           ANIWESH TIMES\n",
       "3    0.830987        JSRTTMS  DELURD02896           JASARAT TIMES\n",
       "4    0.830987        JSRTTMS  DELBIL06518           JASARAT TIMES\n",
       "..        ...            ...          ...                     ...\n",
       "195  0.165786       TSTJRTMS   MPHIN34395          DASTGEER TIMES\n",
       "196  0.165721        JTXRTMS  RAJHIN27392        JODHESHWAR TIMES\n",
       "197  0.165661         MJTTMS   UPHIN47530            MAJEET TIMES\n",
       "198  0.165532    RXTRLKMTTMS   UPHIN49259  RASHTRIYA LOKMAT TIMES\n",
       "199  0.165407        ATRXTMS   UPHIN13828            ADARSH TIMES\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_results(name=0.8,meta=0.2,title=\"INDIAN\"):\n",
    "    processed_results = []\n",
    "    nameVector=[model.encode(title).tolist()]\n",
    "    metaphoneVector=[model.encode(get_metaphone(title)).tolist()]\n",
    "    search_param_1 = {\n",
    "    \"data\": nameVector, \n",
    "    \"anns_field\": \"vector_of_name\", \n",
    "    \"param\": {\n",
    "        \"metric_type\": \"COSINE\", \n",
    "        \"params\": {\"nprobe\": 384}\n",
    "    },\n",
    "    \"limit\": 200,\n",
    "    }\n",
    "    search_param_2 = {\n",
    "    \"data\": metaphoneVector, \n",
    "    \"anns_field\": \"vector_of_metaphone\", \n",
    "    \"param\": {\n",
    "        \"metric_type\": \"COSINE\",\n",
    "        \"params\": {\"nprobe\": 384}\n",
    "    },\n",
    "    \"limit\": 200,\n",
    "    }\n",
    "    reqs = [AnnSearchRequest(**search_param_1), AnnSearchRequest(**search_param_2)]\n",
    "    rerank = WeightedRanker(name, meta)\n",
    "    results = collection.hybrid_search(\n",
    "    reqs,\n",
    "    rerank,\n",
    "    limit=200,\n",
    "    output_fields=[\"Metaphone_Name\",\"Title_Name\",'Count']\n",
    "    )\n",
    "    for result in results[0]:\n",
    "        processed_results.append({\n",
    "            \"distance\": result.distance,\n",
    "            \"Metaphone_Name\": result.entity.get(\"Metaphone_Name\"),\n",
    "            \"Title_Name\": result.entity.get(\"Title_Name\"),\n",
    "            \"Count\":result.entity.get(\"Count\")\n",
    "        })\n",
    "    df=pd.DataFrame(processed_results)\n",
    "    df=df.sort_values(by=['distance',\"Count\"],ascending=False)[:50]\n",
    "    return df.loc[df['Count']>100]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_search_results=create_hybrid_results(0.8,0.2,'AND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word THE or similar to it matches with 10.78 of total names\n",
      "the word INDIAN or similar to it matches with 39.63 of total names\n"
     ]
    }
   ],
   "source": [
    "entered_name=\"PERIN THE INDIAN\"\n",
    "for name in entered_name.split():\n",
    "    result=create_hybrid_results(0.8,0.2,name)\n",
    "    result=result.loc[result['distance']>0.80]\n",
    "    if(result.shape[0]>0):\n",
    "        print(f\"the word {name} or similar to it matches with {((sum(result['Count'])*100)/10000)} of total names\")\n",
    "    # print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>Metaphone_Name</th>\n",
       "      <th>Title_Name</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0</td>\n",
       "      <td>THE</td>\n",
       "      <td>1078.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.698457</td>\n",
       "      <td>N</td>\n",
       "      <td>NEW</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.594116</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALL</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance Metaphone_Name Title_Name   Count\n",
       "0  0.999999              0        THE  1078.0\n",
       "1  0.698457              N        NEW   132.0\n",
       "2  0.594116             AL        ALL   128.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts=pd.read_csv('../dataFiles/word_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(word_counts.shape[0]):\n",
    "    name=word_counts.iloc[i]['Title_Name']\n",
    "    count=word_counts.iloc[i]['Word_Count']\n",
    "    word_list.append({\n",
    "        'Title_Name':name,\n",
    "        'Count':float(count),\n",
    "        'Metaphone_Name':doublemetaphone(name)[0],\n",
    "        'vector_of_name':model.encode(name).tolist(),\n",
    "        'vector_of_metaphone':model.encode(doublemetaphone(name)[0]).tolist()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = {\n",
    "    \"rows\": word_list\n",
    "}\n",
    "with open(\"word_count_two_vector.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(output_json, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pronouncing\n",
      "  Downloading pronouncing-0.2.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cmudict>=0.4.0 (from pronouncing)\n",
      "  Downloading cmudict-1.0.31-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: importlib-metadata>=5 in c:\\users\\modip\\anaconda3\\envs\\sarthi\\lib\\site-packages (from cmudict>=0.4.0->pronouncing) (8.5.0)\n",
      "Collecting importlib-resources>=5 (from cmudict>=0.4.0->pronouncing)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\modip\\anaconda3\\envs\\sarthi\\lib\\site-packages (from importlib-metadata>=5->cmudict>=0.4.0->pronouncing) (3.21.0)\n",
      "Downloading cmudict-1.0.31-py3-none-any.whl (939 kB)\n",
      "   ---------------------------------------- 0.0/939.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 939.4/939.4 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: pronouncing\n",
      "  Building wheel for pronouncing (setup.py): started\n",
      "  Building wheel for pronouncing (setup.py): finished with status 'done'\n",
      "  Created wheel for pronouncing: filename=pronouncing-0.2.0-py2.py3-none-any.whl size=6258 sha256=3e8453eb00788a7af9ac4cfecc1daba64d4a6d019b512181c13af68e8df5358e\n",
      "  Stored in directory: c:\\users\\modip\\appdata\\local\\pip\\cache\\wheels\\05\\f6\\1d\\599c67da1fa48c086d8c49e8fc6bd5f05bc9fa66fb04bed5db\n",
      "Successfully built pronouncing\n",
      "Installing collected packages: importlib-resources, cmudict, pronouncing\n",
      "Successfully installed cmudict-1.0.31 importlib-resources-6.4.5 pronouncing-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARPAbet phonemes for progress: P R AA1 G R EH2 S\n"
     ]
    }
   ],
   "source": [
    "import pronouncing\n",
    "\n",
    "# Example word\n",
    "word = \"progress\"\n",
    "\n",
    "# Get ARPAbet transcriptions for the word\n",
    "pronunciations = pronouncing.phones_for_word(word)\n",
    "\n",
    "# Print the first phoneme transcription\n",
    "if pronunciations:\n",
    "    print(f\"ARPAbet phonemes for {word}: {pronunciations[0]}\")\n",
    "else:\n",
    "    print(f\"No ARPAbet transcription found for {word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello -> HHEHLLAH\n",
      "world -> WAHRLD\n",
      "ONE23 -> AHNEH23\n",
      "2008 -> 2008\n",
      "boom! -> BAHAHM\n",
      "kweezlebotter -> KWEHEHZLEHBAHTTEHR\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_phonetic_transcription(word):\n",
    "    # Convert to lowercase for consistency\n",
    "    word = word.lower()\n",
    "\n",
    "    # Vowel mapping (ARPAbet)\n",
    "    vowel_map = {\n",
    "        'a': 'AE', 'e': 'EH', 'i': 'IH', 'o': 'AH', 'u': 'UH', \n",
    "        'ai': 'EY', 'ei': 'EY', 'oi': 'OY', 'ou': 'OW', 'au': 'AW',\n",
    "        'oo': 'UW', 'ea': 'IY', 'ea': 'EH', 'ay': 'EY', 'ey': 'EH'\n",
    "    }\n",
    "    \n",
    "    # Consonant mapping (ARPAbet)\n",
    "    consonant_map = {\n",
    "        'b': 'B', 'c': 'K', 'd': 'D', 'f': 'F', 'g': 'G', \n",
    "        'h': 'HH', 'j': 'JH', 'k': 'K', 'l': 'L', 'm': 'M', \n",
    "        'n': 'N', 'p': 'P', 'q': 'K', 'r': 'R', 's': 'S', \n",
    "        't': 'T', 'v': 'V', 'w': 'W', 'x': 'KS', 'y': 'Y', 'z': 'Z'\n",
    "    }\n",
    "    \n",
    "    # Handling numbers: Convert numbers to phonetic representation\n",
    "    number_map = {\n",
    "        '0': 'Z', '1': 'W AH N', '2': 'T UW', '3': 'TH R IY', \n",
    "        '4': 'F AO R', '5': 'F AY V', '6': 'S IH K S', \n",
    "        '7': 'S EH V AH N', '8': 'EY T', '9': 'N AY N'\n",
    "    }\n",
    "\n",
    "    # Handle special characters like hyphens and exclamation marks by removing or replacing\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)  # Remove punctuation marks\n",
    "\n",
    "    # Check if the word contains digits and convert them\n",
    "    word_with_digits = \" \".join([number_map.get(ch, ch) for ch in word if ch.isdigit()])\n",
    "\n",
    "    # Handle vowels and consonants for the word\n",
    "    for vowel_pair, phoneme in vowel_map.items():\n",
    "        word = re.sub(vowel_pair, phoneme, word)\n",
    "    \n",
    "    # Replace consonants\n",
    "    phonetic_word = ''.join([consonant_map.get(char, char) for char in word])\n",
    "\n",
    "    # Apply stress (simplified rule for example)\n",
    "    if word in [\"progress\", \"record\"]:\n",
    "        phonetic_word = re.sub(r'([AEIOU])', r'\\1(1)', phonetic_word, count=1)  # Primary stress on first vowel\n",
    "    \n",
    "    return phonetic_word.upper()\n",
    "\n",
    "# Example usage\n",
    "word_list = [\"Hello\", \"world\", \"ONE23\", \"2008\", \"boom!\", \"kweezlebotter\"]\n",
    "\n",
    "lexicon = {}\n",
    "for word in word_list:\n",
    "    phonetic_transcription = get_phonetic_transcription(word)\n",
    "    lexicon[word] = phonetic_transcription\n",
    "\n",
    "# Print lexicon\n",
    "for word, transcription in lexicon.items():\n",
    "    print(f\"{word} -> {transcription}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarthi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
